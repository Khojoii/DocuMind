{"cells":[{"cell_type":"markdown","metadata":{"id":"tQN7JmaPVVGs"},"source":["# Installing packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BHphXwGAQEv6"},"outputs":[],"source":["!pip install -q langchain langchain-community langchain-openai chromadb python-dotenv\n"]},{"cell_type":"markdown","metadata":{"id":"dJkaUC_4jYxf"},"source":["## importing packages\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LX0tINuNV0zf"},"outputs":[],"source":["from langchain_community.document_loaders import TextLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.schema import Document\n","from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n","from langchain_community.vectorstores import Chroma\n","from langchain.prompts import ChatPromptTemplate\n","import openai\n","import os\n","import shutil\n","import argparse"]},{"cell_type":"markdown","source":["## connect to OpenAI gpt API\n","To connect to the OpenAI GPT API, we utilized [AvalAi](https://avalai.ir/). After signing in, we generated an API key specifically for our project."],"metadata":{"id":"-8jubs_M2iVw"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":721,"status":"ok","timestamp":1754105970626,"user":{"displayName":"محمد حسین","userId":"13927992254442647854"},"user_tz":-210},"id":"77jzeYJdkyLe","outputId":"f3212b2d-1269-46f7-fe46-28d390ee72c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["content='Hello! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 20, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'text_tokens': None, 'image_tokens': None}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'id': 'chatcmpl-BzxNhmuRhKuawWZ8IuKwpCE1chqrT', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--8e971a33-f561-4f92-a786-7ca5450810c5-0' usage_metadata={'input_tokens': 20, 'output_tokens': 10, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n","Tokens Used: 30\n","\tPrompt Tokens: 20\n","\t\tPrompt Tokens Cached: 0\n","\tCompletion Tokens: 10\n","\t\tReasoning Tokens: 0\n","Successful Requests: 1\n","Total Cost (USD): $8.999999999999999e-06\n"]}],"source":["from langchain_openai import ChatOpenAI\n","from langchain_community.callbacks import get_openai_callback\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Hello world!\"},\n","]\n","\n","model_name = \"gpt-4o-mini\" # in this case we want to use gpt-4o-mini\n","\n","llm = ChatOpenAI(\n","    model=model_name,\n","    base_url=\"https://api.avalai.ir/v1\",\n","    temperature=0,\n","    max_tokens=None,\n","    max_retries=0,\n","    api_key=\"aa-**\"\n",")\n","# this is testing the API connection and tracking token usage\n","with get_openai_callback() as cb:\n","    response = llm.invoke(messages)\n","    print(response)\n","    print(cb)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"14IKSZe1mHXb"},"outputs":[],"source":["CHROMA_PATH = \"/content/chroma\" # Path of our data base DIR"]},{"cell_type":"markdown","source":["# Data preprocessing"],"metadata":{"id":"3xPJOuHG3S59"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_vnllU79m86t"},"outputs":[],"source":["def load_documents(Data): #this will load our data into document\n","    loader = TextLoader(Data)\n","    documents = loader.load()\n","    return documents\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"55BNY1BonAhz"},"outputs":[],"source":["def split_text(documents: list[Document]): # a text splitter to divide documents into smaller parts (chunks)\n","    text_splitter = RecursiveCharacterTextSplitter(\n","        chunk_size=500, # Each chunk will have up to 500 characters\n","        chunk_overlap=100, # Each chunk will overlap with the previous one by 100 characters\n","        length_function=len,\n","        add_start_index=True,\n","    )\n","    chunks = text_splitter.split_documents(documents)\n","    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n","\n","    document = chunks[10]\n","    print(document.page_content)\n","    print(document.metadata)\n","\n","    return chunks\n"]},{"cell_type":"markdown","source":["## Create and save chroma data base\n","\n","\n","\n"],"metadata":{"id":"ojmUvbxT5Rdr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SqjiYg9mnNp6"},"outputs":[],"source":["from chromadb.config import Settings\n","import time # Import time\n","\n","def save_to_chroma(chunks: list[Document]):\n","    # if path exists remove\n","    if os.path.exists(CHROMA_PATH):\n","        print(f\"Removing existing directory: {CHROMA_PATH}\")\n","        shutil.rmtree(CHROMA_PATH)\n","        time.sleep(1) # Add a small delay after removal\n","\n","    # if not exists create\n","    print(f\"Creating directory: {CHROMA_PATH}\")\n","    os.makedirs(CHROMA_PATH, exist_ok=True)\n","\n","    # Create a new Chroma collection from documents\n","    db = Chroma.from_documents(\n","        chunks,\n","        OpenAIEmbeddings(\n","            api_key=\"aa-***\",\n","            base_url=\"https://api.avalai.ir/v1\"\n","        ),\n","        # persist_directory=CHROMA_PATH\n","    )\n","\n","    print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")\n","    return db"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4817,"status":"ok","timestamp":1754105736752,"user":{"displayName":"محمد حسین","userId":"13927992254442647854"},"user_tz":-210},"id":"36nrIk8jnPB-","outputId":"e58af6aa-5d3f-4bc4-d402-ccd0d9a4e80a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Split 1 documents into 435 chunks.\n","All the animals were now present except Moses, the tame raven, who slept\n","on a perch behind the back door. When Major saw that they had all made\n","themselves comfortable and were waiting attentively, he cleared his throat and\n","began:\n","`Comrades, you have heard already about the strange dream that I had last\n","night. But I will come to the dream later. I have something else to say \frst. I\n","do not think, comrades, that I shall be with you for many months longer, and\n","{'source': 'animal farm.md', 'start_index': 3947}\n","Removing existing directory: /content/chroma\n","Creating directory: /content/chroma\n","Saved 435 chunks to /content/chroma.\n"]},{"output_type":"execute_result","data":{"text/plain":["<langchain_community.vectorstores.chroma.Chroma at 0x794dd3bc9790>"]},"metadata":{},"execution_count":52}],"source":["documents = load_documents(\"your_document.md\")\n","chunks = split_text(documents)\n","save_to_chroma(chunks)"]},{"cell_type":"markdown","source":["# How to use the model"],"metadata":{"id":"7JE93AbN5nh9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eYzU_8mrTpVc"},"outputs":[],"source":["# a template for the model's answer\n","PROMPT_TEMPLATE = \"\"\"\n","Answer the question based only on the following context:\n","\n","{context}\n","\n","---\n","\n","Answer the question based on the above context: {question}\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9wtSZPdWoSkf"},"outputs":[],"source":["def query():\n","    question = input(\"Ask your question: \")\n","    query_text = question\n","     # Perform similarity search with relevance scores using the user's question\n","    results = db.similarity_search_with_relevance_scores(query_text, k=2) # k=2 means Find the 2 most relevant document chunks for the query\n","\n","    if len(results) == 0 or results[0][1] < 0.7:\n","        print(\"Unable to find matching results.\")\n","    else:\n","        context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _ in results])\n","        prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n","        prompt = prompt_template.format(context=context_text, question=query_text)\n","        print(\"Prompt:\\n\", prompt)\n","\n","        # Use the existing llm object and its invoke method\n","        response = llm.invoke(prompt)\n","        response_text = response.content\n","\n","        sources = [doc.metadata.get(\"source\", None) for doc, _ in results]\n","        formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n","        print(formatted_response)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9386,"status":"ok","timestamp":1754105746163,"user":{"displayName":"محمد حسین","userId":"13927992254442647854"},"user_tz":-210},"id":"SWfNqV0MogqV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b864302d-7895-49fe-de28-08a299536f13"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ask your question: is there any horses ?\n","Prompt:\n"," Human: \n","Answer the question based only on the following context:\n","\n","hairy hoofs with great care lest there should be some small animal concealed in\n","the straw. Clover was a stout motherly mare approaching middle life, who had\n","never quite got her \fgure back after her fourth foal. Boxer was an enormous\n","beast, nearly eighteen hands high, and as strong as any two ordinary horses put\n","together. A white stripe down his nose gave him a somewhat stupid appearance,\n","and in fact he was not of \frst-rate intelligence, but he was universally respected\n","for his steadiness of character and tremendous powers of work. After the horses\n","came Muriel, the white goat, and Benjamin, the donkey. Benjamin was the\n","oldest animal on the farm, and the worst tempered. He seldom talked, and\n","when he did, it was usually to make some cynical remark | for instance, he\n","\n","---\n","\n","hairy hoofs with great care lest there should be some small animal concealed in\n","the straw. Clover was a stout motherly mare approaching middle life, who had\n","never quite got her \fgure back after her fourth foal. Boxer was an enormous\n","beast, nearly eighteen hands high, and as strong as any two ordinary horses put\n","together. A white stripe down his nose gave him a somewhat stupid appearance,\n","and in fact he was not of \frst-rate intelligence, but he was universally respected\n","for his steadiness of character and tremendous powers of work. After the horses\n","came Muriel, the white goat, and Benjamin, the donkey. Benjamin was the\n","oldest animal on the farm, and the worst tempered. He seldom talked, and\n","when he did, it was usually to make some cynical remark | for instance, he\n","\n","---\n","\n","hairy hoofs with great care lest there should be some small animal concealed in\n","the straw. Clover was a stout motherly mare approaching middle life, who had\n","never quite got her \fgure back after her fourth foal. Boxer was an enormous\n","beast, nearly eighteen hands high, and as strong as any two ordinary horses put\n","together. A white stripe down his nose gave him a somewhat stupid appearance,\n","and in fact he was not of \frst-rate intelligence, but he was universally respected\n","for his steadiness of character and tremendous powers of work. After the horses\n","came Muriel, the white goat, and Benjamin, the donkey. Benjamin was the\n","oldest animal on the farm, and the worst tempered. He seldom talked, and\n","when he did, it was usually to make some cynical remark | for instance, he\n","\n","---\n","\n","Answer the question based on the above context: is there any horses ?\n","\n","Response: Yes, there are horses mentioned in the context. Specifically, Clover and Boxer are described as horses.\n","Sources: ['animal farm.md', 'animal farm.md', 'animal farm.md']\n"]}],"source":["query()"]},{"cell_type":"code","source":[],"metadata":{"id":"I5KPizN21l_t"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhH9LIXWRdtBzB//RG37Xd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}